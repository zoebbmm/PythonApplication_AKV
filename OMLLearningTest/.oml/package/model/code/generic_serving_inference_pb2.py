# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: generic_serving_inference.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import service as _service
from google.protobuf import service_reflection
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor.FileDescriptor(
  name='generic_serving_inference.proto',
  package='tensorflow.serving',
  syntax='proto3',
  serialized_pb=_b('\n\x1fgeneric_serving_inference.proto\x12\x12tensorflow.serving\"\x1e\n\x0eGenericRequest\x12\x0c\n\x04\x64\x61ta\x18\x01 \x01(\t\"\x1f\n\x0fGenericResponse\x12\x0c\n\x04\x64\x61ta\x18\x01 \x01(\t2a\n\x0eGenericService\x12O\n\x04\x45val\x12\".tensorflow.serving.GenericRequest\x1a#.tensorflow.serving.GenericResponseB\x03\x90\x01\x01\x62\x06proto3')
)
_sym_db.RegisterFileDescriptor(DESCRIPTOR)




_GENERICREQUEST = _descriptor.Descriptor(
  name='GenericRequest',
  full_name='tensorflow.serving.GenericRequest',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='data', full_name='tensorflow.serving.GenericRequest.data', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=55,
  serialized_end=85,
)


_GENERICRESPONSE = _descriptor.Descriptor(
  name='GenericResponse',
  full_name='tensorflow.serving.GenericResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='data', full_name='tensorflow.serving.GenericResponse.data', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=87,
  serialized_end=118,
)

DESCRIPTOR.message_types_by_name['GenericRequest'] = _GENERICREQUEST
DESCRIPTOR.message_types_by_name['GenericResponse'] = _GENERICRESPONSE

GenericRequest = _reflection.GeneratedProtocolMessageType('GenericRequest', (_message.Message,), dict(
  DESCRIPTOR = _GENERICREQUEST,
  __module__ = 'generic_serving_inference_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.GenericRequest)
  ))
_sym_db.RegisterMessage(GenericRequest)

GenericResponse = _reflection.GeneratedProtocolMessageType('GenericResponse', (_message.Message,), dict(
  DESCRIPTOR = _GENERICRESPONSE,
  __module__ = 'generic_serving_inference_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.GenericResponse)
  ))
_sym_db.RegisterMessage(GenericResponse)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\220\001\001'))

_GENERICSERVICE = _descriptor.ServiceDescriptor(
  name='GenericService',
  full_name='tensorflow.serving.GenericService',
  file=DESCRIPTOR,
  index=0,
  options=None,
  serialized_start=120,
  serialized_end=217,
  methods=[
  _descriptor.MethodDescriptor(
    name='Eval',
    full_name='tensorflow.serving.GenericService.Eval',
    index=0,
    containing_service=None,
    input_type=_GENERICREQUEST,
    output_type=_GENERICRESPONSE,
    options=None,
  ),
])

GenericService = service_reflection.GeneratedServiceType('GenericService', (_service.Service,), dict(
  DESCRIPTOR = _GENERICSERVICE,
  __module__ = 'generic_serving_inference_pb2'
  ))

GenericService_Stub = service_reflection.GeneratedServiceStubType('GenericService_Stub', (GenericService,), dict(
  DESCRIPTOR = _GENERICSERVICE,
  __module__ = 'generic_serving_inference_pb2'
  ))


import grpc
from grpc.beta import implementations as beta_implementations
from grpc.beta import interfaces as beta_interfaces
from grpc.framework.common import cardinality
from grpc.framework.interfaces.face import utilities as face_utilities


class GenericServiceStub(object):

  def __init__(self, channel):
    """Constructor.

    Args:
      channel: A grpc.Channel.
    """
    self.Eval = channel.unary_unary(
        '/tensorflow.serving.GenericService/Eval',
        request_serializer=GenericRequest.SerializeToString,
        response_deserializer=GenericResponse.FromString,
        )


class GenericServiceServicer(object):

  def Eval(self, request, context):
    """Classifies image into digits.
    """
    context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    context.set_details('Method not implemented!')
    raise NotImplementedError('Method not implemented!')


def add_GenericServiceServicer_to_server(servicer, server):
  rpc_method_handlers = {
      'Eval': grpc.unary_unary_rpc_method_handler(
          servicer.Eval,
          request_deserializer=GenericRequest.FromString,
          response_serializer=GenericResponse.SerializeToString,
      ),
  }
  generic_handler = grpc.method_handlers_generic_handler(
      'tensorflow.serving.GenericService', rpc_method_handlers)
  server.add_generic_rpc_handlers((generic_handler,))


class BetaGenericServiceServicer(object):
  def Eval(self, request, context):
    """Classifies image into digits.
    """
    context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


class BetaGenericServiceStub(object):
  def Eval(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
    """Classifies image into digits.
    """
    raise NotImplementedError()
  Eval.future = None


def beta_create_GenericService_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
  request_deserializers = {
    ('tensorflow.serving.GenericService', 'Eval'): GenericRequest.FromString,
  }
  response_serializers = {
    ('tensorflow.serving.GenericService', 'Eval'): GenericResponse.SerializeToString,
  }
  method_implementations = {
    ('tensorflow.serving.GenericService', 'Eval'): face_utilities.unary_unary_inline(servicer.Eval),
  }
  server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
  return beta_implementations.server(method_implementations, options=server_options)


def beta_create_GenericService_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
  request_serializers = {
    ('tensorflow.serving.GenericService', 'Eval'): GenericRequest.SerializeToString,
  }
  response_deserializers = {
    ('tensorflow.serving.GenericService', 'Eval'): GenericResponse.FromString,
  }
  cardinalities = {
    'Eval': cardinality.Cardinality.UNARY_UNARY,
  }
  stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
  return beta_implementations.dynamic_stub(channel, 'tensorflow.serving.GenericService', cardinalities, options=stub_options)
# @@protoc_insertion_point(module_scope)
